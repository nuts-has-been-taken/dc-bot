"""LLM Job Search Integration Example."""

import json
import time
from typing import Dict, Any
from ..llm.client import call_llm, extract_tool_calls
from ..llm.tools import (
    JOB_SEARCH_TOOL,
    execute_job_search_tool,
    format_job_search_results,
)
from .prompt import JOB_SEARCH_FINAL_RESPONSE_PROMPT


def chat_with_job_search(
    user_message: str
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ LLM é€²è¡Œå·¥ä½œæœå°‹å°è©±ã€‚

    Args:
        user_message: ç”¨æˆ¶çš„è¨Šæ¯

    Returns:
        åŒ…å«å®Œæ•´è¨˜éŒ„çš„å­—å…¸ï¼š
        {
            "user_message": str,              # ç”¨æˆ¶è¨Šæ¯
            "tool_calls": List[Dict],         # å·¥å…·å‘¼å«è¨˜éŒ„
            "search_results": List[Dict],     # æœå°‹çµæœ
            "final_response": str,            # LLM æœ€çµ‚å›æ‡‰
            "has_tool_call": bool,            # æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
        }

    Example:
        >>> # ä½¿ç”¨ .env ä¸­çš„è¨­å®š
        >>> result = chat_with_job_search(
        ...     "æˆ‘æƒ³æ‰¾å°åŒ—å¸‚çš„ Python å·¥ç¨‹å¸«å·¥ä½œï¼Œè–ªæ°´è‡³å°‘ 5 è¬"
        ... )
        >>> print(result["final_response"])
        >>> print(result["tool_calls"])
    """
    # æº–å‚™è¿”å›çµæœ
    result = {
        "user_message": user_message,
        "tool_calls": [],
        "search_results": [],
        "final_response": "",
        "has_tool_call": False,
    }

    # æº–å‚™å°è©±è¨Šæ¯
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ±‚è·åŠ©æ‰‹ï¼Œå¹«åŠ©ç”¨æˆ¶åœ¨ 104 äººåŠ›éŠ€è¡Œæœå°‹å·¥ä½œæ©Ÿæœƒã€‚ç•¶ç”¨æˆ¶æè¿°ä»–å€‘æƒ³æ‰¾çš„å·¥ä½œæ™‚ï¼Œè«‹ä½¿ç”¨ search_104_jobs å·¥å…·ä¾†æœå°‹",
        },
        {
            "role": "user",
            "content": user_message,
        },
    ]

    # æº–å‚™å·¥å…·å®šç¾©
    tools = [JOB_SEARCH_TOOL]

    # ç¬¬ä¸€æ¬¡å‘¼å« LLM
    print("ğŸ¤– å‘¼å« LLM ä¸­...")
    start_time = time.time()
    llm_response = call_llm(
        messages=messages,
        tools=tools,
    )
    llm_time = time.time() - start_time

    # é¡¯ç¤ºç¬¬ä¸€æ¬¡ LLM å‘¼å«çš„æ™‚é–“å’Œ token ä½¿ç”¨é‡
    print(f"â±ï¸  ç¬¬ä¸€æ¬¡ LLM å‘¼å«è€—æ™‚: {llm_time:.2f} ç§’")
    if "usage" in llm_response:
        usage = llm_response["usage"]
        print(f"ğŸ“Š Token ä½¿ç”¨é‡: {usage.get('total_tokens', 0)} tokens "
              f"(prompt: {usage.get('prompt_tokens', 0)}, "
              f"completion: {usage.get('completion_tokens', 0)})")

    # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·å‘¼å«
    tool_calls = extract_tool_calls(llm_response)

    if not tool_calls:
        # æ²’æœ‰å·¥å…·å‘¼å«ï¼Œç›´æ¥è¿”å› LLM çš„å›æ‡‰
        result["final_response"] = llm_response["choices"][0]["message"]["content"]
        return result

    # åŸ·è¡Œå·¥å…·å‘¼å«
    result["has_tool_call"] = True
    print(f"ğŸ”§ åŸ·è¡Œå·¥å…·å‘¼å«ï¼š{len(tool_calls)} å€‹")

    for tool_call in tool_calls:
        if tool_call["name"] == "search_104_jobs":
            print(f"   åƒæ•¸ï¼š{json.dumps(tool_call['arguments'], ensure_ascii=False, indent=2)}")

            # è¨˜éŒ„å·¥å…·è¼¸å…¥åƒæ•¸
            tool_call_record = {
                "tool_name": tool_call["name"],
                "parameters": tool_call["arguments"],
            }
            result["tool_calls"].append(tool_call_record)

            # åŸ·è¡Œå·¥ä½œæœå°‹
            print("ğŸ•·ï¸  åŸ·è¡Œ 104 å·¥ä½œæœå°‹...")
            crawler_start_time = time.time()
            search_result = execute_job_search_tool(tool_call["arguments"])
            crawler_time = time.time() - crawler_start_time
            print(f"â±ï¸  çˆ¬èŸ²åŸ·è¡Œè€—æ™‚: {crawler_time:.2f} ç§’")

            # è¨˜éŒ„æŸ¥è©¢çµæœ
            result["search_results"].append(search_result)

            # æ ¼å¼åŒ–çµæœ
            formatted_result = format_job_search_results(search_result)

            # å°‡å·¥å…·åŸ·è¡ŒçµæœåŠ å…¥å°è©±
            messages.append(llm_response["choices"][0]["message"])
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call["id"],
                "name": tool_call["name"],
                "content": formatted_result,
            })
    
    # æŒ‡å° LLM ç”Ÿæˆæœ€çµ‚å›æ‡‰
    messages.append({
        "role": "system",
        "content": JOB_SEARCH_FINAL_RESPONSE_PROMPT,
    })

    # ç¬¬äºŒæ¬¡å‘¼å« LLMï¼Œè®“å®ƒæ ¹æ“šå·¥å…·çµæœç”Ÿæˆå›æ‡‰
    print("ğŸ¤– ç”Ÿæˆæœ€çµ‚å›æ‡‰ä¸­...")
    final_start_time = time.time()
    final_response = call_llm(
        messages=messages,
    )
    final_llm_time = time.time() - final_start_time

    # é¡¯ç¤ºç¬¬äºŒæ¬¡ LLM å‘¼å«çš„æ™‚é–“å’Œ token ä½¿ç”¨é‡
    print(f"â±ï¸  æœ€çµ‚å›æ‡‰ç”Ÿæˆè€—æ™‚: {final_llm_time:.2f} ç§’")
    if "usage" in final_response:
        usage = final_response["usage"]
        print(f"ğŸ“Š Token ä½¿ç”¨é‡: {usage.get('total_tokens', 0)} tokens "
              f"(prompt: {usage.get('prompt_tokens', 0)}, "
              f"completion: {usage.get('completion_tokens', 0)})")

    # è¨˜éŒ„æœ€çµ‚å›æ‡‰
    result["final_response"] = final_response["choices"][0]["message"]["content"]

    return result
