"""Job Detail Analysis Workflow."""

import time
from typing import Dict, Any
from ..llm.client import call_llm
from .prompt import JOB_DETAIL_ANALYSIS_PROMPT


def analyze_job_detail(job_query: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ LLM åˆ†æç‰¹å®šè·ç¼ºçš„è©³ç´°è³‡è¨Šã€‚

    æ­¤å‡½æ•¸åˆ©ç”¨ LLM å…§å»ºçš„ web search åŠŸèƒ½ï¼ŒæŸ¥è©¢è·ç¼ºç›¸é—œçš„å…¬å¸èƒŒæ™¯ã€
    è·ä½è¦æ±‚ã€å“¡å·¥è©•åƒ¹ç­‰è³‡è¨Šï¼Œä¸¦ç”Ÿæˆåˆ†æå ±å‘Šã€‚

    Args:
        job_query: è·ç¼ºæŸ¥è©¢è³‡è¨Šï¼Œæ‡‰åŒ…å«è·ä½åç¨±ã€å…¬å¸åç¨±ç­‰åŸºæœ¬æè¿°ã€‚
                  ç¯„ä¾‹ï¼šã€ŒæŸç§‘æŠ€å…¬å¸çš„ Python å¾Œç«¯å·¥ç¨‹å¸«ã€æˆ–
                        ã€Œ104 è·ç¼ºé€£çµï¼šhttps://www.104.com.tw/job/xxxxxã€

    Returns:
        åŒ…å«åˆ†æçµæœçš„å­—å…¸ï¼š
        {
            "job_query": str,                # è¼¸å…¥çš„è·ç¼ºæŸ¥è©¢
            "analysis_report": str,          # LLM ç”Ÿæˆçš„åˆ†æå ±å‘Š
            "processing_time": float,        # è™•ç†æ™‚é–“ï¼ˆç§’ï¼‰
            "token_usage": Dict,             # Token ä½¿ç”¨é‡çµ±è¨ˆ
        }

    Example:
        >>> result = analyze_job_detail("æŸç§‘æŠ€å…¬å¸çš„ Python å¾Œç«¯å·¥ç¨‹å¸«")
        >>> print(result["analysis_report"])

        >>> # ä¹Ÿå¯ä»¥ç›´æ¥å‚³å…¥ 104 é€£çµ
        >>> result = analyze_job_detail("https://www.104.com.tw/job/xxxxx")
        >>> print(result["analysis_report"])
    """

    # æº–å‚™è¿”å›çµæœ
    result = {
        "job_query": job_query,
        "analysis_report": "",
        "processing_time": 0.0,
        "token_usage": {},
    }

    # ä½¿ç”¨ LLM é€²è¡Œåˆ†æ
    print("ğŸ¤– åˆ†æè·ç¼ºè©³ç´°è³‡è¨Šä¸­...")

    messages = [
        {
            "role": "system",
            "content": JOB_DETAIL_ANALYSIS_PROMPT.format(job_info=job_query),
        },
        {
            "role": "user",
            "content": "è«‹é–‹å§‹åˆ†æé€™å€‹è·ç¼ºã€‚",
        },
    ]

    start_time = time.time()
    llm_response = call_llm(messages=messages)
    processing_time = time.time() - start_time

    result["processing_time"] = processing_time

    # é¡¯ç¤ºè™•ç†æ™‚é–“å’Œ token ä½¿ç”¨é‡
    print(f"â±ï¸  åˆ†æè€—æ™‚: {processing_time:.2f} ç§’")
    if "usage" in llm_response:
        usage = llm_response["usage"]
        result["token_usage"] = {
            "total": usage.get("total_tokens", 0),
            "prompt": usage.get("prompt_tokens", 0),
            "completion": usage.get("completion_tokens", 0),
        }
        print(f"ğŸ“Š Token ä½¿ç”¨é‡: {usage.get('total_tokens', 0)} tokens "
              f"(prompt: {usage.get('prompt_tokens', 0)}, "
              f"completion: {usage.get('completion_tokens', 0)})")

    # æå–åˆ†æå ±å‘Š
    result["analysis_report"] = llm_response["choices"][0]["message"]["content"]
    print(f"ğŸ“ å ±å‘Šé•·åº¦ï¼š{len(result['analysis_report'])} å­—å…ƒ")

    return result
