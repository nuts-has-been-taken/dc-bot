"""LLM Job Search Integration Example."""

import json
from typing import Dict, Any, List, Optional
from llm_client import call_llm, extract_tool_calls
from job_search_tool import (
    JOB_SEARCH_TOOL,
    execute_job_search_tool,
    format_job_search_results,
)


def chat_with_job_search(
    user_message: str,
    api_key: Optional[str] = None,
    api_url: Optional[str] = None,
    model: Optional[str] = None,
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ LLM é€²è¡Œå·¥ä½œæœå°‹å°è©±ã€‚

    Args:
        user_message: ç”¨æˆ¶çš„è¨Šæ¯
        api_key: LLM API é‡‘é‘°ï¼ˆé è¨­å¾ .env è®€å–ï¼‰
        api_url: LLM API ç«¯é»ï¼ˆé è¨­å¾ .env è®€å–ï¼‰
        model: æ¨¡å‹åç¨±ï¼ˆé è¨­å¾ .env è®€å–ï¼‰

    Returns:
        åŒ…å«å®Œæ•´è¨˜éŒ„çš„å­—å…¸ï¼š
        {
            "user_message": str,              # ç”¨æˆ¶è¨Šæ¯
            "tool_calls": List[Dict],         # å·¥å…·å‘¼å«è¨˜éŒ„
            "search_results": List[Dict],     # æœå°‹çµæœ
            "final_response": str,            # LLM æœ€çµ‚å›æ‡‰
            "has_tool_call": bool,            # æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
        }

    Example:
        >>> # ä½¿ç”¨ .env ä¸­çš„è¨­å®š
        >>> result = chat_with_job_search(
        ...     "æˆ‘æƒ³æ‰¾å°åŒ—å¸‚çš„ Python å·¥ç¨‹å¸«å·¥ä½œï¼Œè–ªæ°´è‡³å°‘ 5 è¬"
        ... )
        >>> print(result["final_response"])
        >>> print(result["tool_calls"])
    """
    # æº–å‚™è¿”å›çµæœ
    result = {
        "user_message": user_message,
        "tool_calls": [],
        "search_results": [],
        "final_response": "",
        "has_tool_call": False,
    }

    # æº–å‚™å°è©±è¨Šæ¯
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ±‚è·åŠ©æ‰‹ï¼Œå¹«åŠ©ç”¨æˆ¶åœ¨ 104 äººåŠ›éŠ€è¡Œæœå°‹å·¥ä½œæ©Ÿæœƒã€‚ç•¶ç”¨æˆ¶æè¿°ä»–å€‘æƒ³æ‰¾çš„å·¥ä½œæ™‚ï¼Œè«‹ä½¿ç”¨ search_104_jobs å·¥å…·ä¾†æœå°‹ï¼Œä¸¦å°‡çµæœæ•´ç†å¾Œå›è¦†çµ¦ç”¨æˆ¶ã€‚",
        },
        {
            "role": "user",
            "content": user_message,
        },
    ]

    # æº–å‚™å·¥å…·å®šç¾©
    tools = [JOB_SEARCH_TOOL]

    # ç¬¬ä¸€æ¬¡å‘¼å« LLM
    print("ğŸ¤– å‘¼å« LLM ä¸­...")
    llm_response = call_llm(
        messages=messages,
        tools=tools,
        api_key=api_key,
        api_url=api_url,
        model=model,
    )

    # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·å‘¼å«
    tool_calls = extract_tool_calls(llm_response)

    if not tool_calls:
        # æ²’æœ‰å·¥å…·å‘¼å«ï¼Œç›´æ¥è¿”å› LLM çš„å›æ‡‰
        result["final_response"] = llm_response["choices"][0]["message"]["content"]
        return result

    # åŸ·è¡Œå·¥å…·å‘¼å«
    result["has_tool_call"] = True
    print(f"ğŸ”§ åŸ·è¡Œå·¥å…·å‘¼å«ï¼š{len(tool_calls)} å€‹")

    for tool_call in tool_calls:
        if tool_call["name"] == "search_104_jobs":
            print(f"   åƒæ•¸ï¼š{json.dumps(tool_call['arguments'], ensure_ascii=False, indent=2)}")

            # è¨˜éŒ„å·¥å…·è¼¸å…¥åƒæ•¸
            tool_call_record = {
                "tool_name": tool_call["name"],
                "parameters": tool_call["arguments"],
            }
            result["tool_calls"].append(tool_call_record)

            # åŸ·è¡Œå·¥ä½œæœå°‹
            search_result = execute_job_search_tool(tool_call["arguments"])

            # è¨˜éŒ„æŸ¥è©¢çµæœ
            result["search_results"].append(search_result)

            # æ ¼å¼åŒ–çµæœ
            formatted_result = format_job_search_results(search_result)

            # å°‡å·¥å…·åŸ·è¡ŒçµæœåŠ å…¥å°è©±
            messages.append(llm_response["choices"][0]["message"])
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call["id"],
                "name": tool_call["name"],
                "content": formatted_result,
            })

    # ç¬¬äºŒæ¬¡å‘¼å« LLMï¼Œè®“å®ƒæ ¹æ“šå·¥å…·çµæœç”Ÿæˆå›æ‡‰
    print("ğŸ¤– ç”Ÿæˆæœ€çµ‚å›æ‡‰ä¸­...")
    final_response = call_llm(
        messages=messages,
        tools=tools,
        api_key=api_key,
        api_url=api_url,
        model=model,
    )

    # è¨˜éŒ„æœ€çµ‚å›æ‡‰
    result["final_response"] = final_response["choices"][0]["message"]["content"]

    return result


def main():
    """
    ä¸»ç¨‹å¼ï¼šç¤ºç¯„å¦‚ä½•ä½¿ç”¨ LLM é€²è¡Œå·¥ä½œæœå°‹ã€‚

    æ³¨æ„ï¼šéœ€è¦åœ¨ .env æ–‡ä»¶ä¸­è¨­å®š LLM_API_KEY å’Œ LLM_API_URL
    """
    from config import config

    print("=" * 60)
    print("LLM å·¥ä½œæœå°‹åŠ©æ‰‹")
    print("=" * 60)
    print()

    # æª¢æŸ¥é…ç½®æ˜¯å¦æ­£ç¢º
    try:
        config.validate()
    except ValueError as e:
        print(f"âš ï¸  é…ç½®éŒ¯èª¤ï¼š{e}")
        print()
        print("ä½¿ç”¨æ–¹å¼ï¼š")
        print("1. è¤‡è£½ .env_example ç‚º .env")
        print("2. åœ¨ .env ä¸­è¨­å®šä½ çš„ API é‡‘é‘°å’Œç«¯é»")
        print("3. é‡æ–°åŸ·è¡Œç¨‹å¼")
        print()
        return

    print(f"âœ“ ä½¿ç”¨æ¨¡å‹ï¼š{config.LLM_MODEL}")
    print(f"âœ“ API URLï¼š{config.LLM_API_URL}")
    print()

    # ç¤ºç¯„å°è©±
    example_queries = [
        "æˆ‘æƒ³æ‰¾å°åŒ—å¸‚çš„ Python å·¥ç¨‹å¸«å·¥ä½œï¼Œè–ªæ°´è‡³å°‘ 5 è¬",
        "å¹«æˆ‘æ‰¾æ–°åŒ—å¸‚çš„å‰ç«¯å·¥ç¨‹å¸«ï¼Œè¦å¤§å­¸ä»¥ä¸Šå­¸æ­·ï¼Œä¸€é€±å…§ç™¼å¸ƒçš„è·ç¼º",
        "æœå°‹å°åŒ—å’Œæ–°åŒ—çš„æ•¸æ“šåˆ†æå¸«å·¥ä½œï¼Œè–ªè³‡ 6-8 è¬",
    ]

    for i, query in enumerate(example_queries, 1):
        print(f"\n{'=' * 60}")
        print(f"ç¯„ä¾‹ {i}")
        print(f"{'=' * 60}")
        print(f"ğŸ‘¤ ç”¨æˆ¶ï¼š{query}")
        print()

        try:
            # ä½¿ç”¨ .env ä¸­çš„é è¨­è¨­å®š
            result = chat_with_job_search(user_message=query)

            # é¡¯ç¤ºå·¥å…·å‘¼å«è¨˜éŒ„
            if result["has_tool_call"]:
                print("ğŸ“ å·¥å…·å‘¼å«è¨˜éŒ„ï¼š")
                for idx, tool_call in enumerate(result["tool_calls"], 1):
                    print(f"   {idx}. {tool_call['tool_name']}")
                    print(f"      åƒæ•¸ï¼š{json.dumps(tool_call['parameters'], ensure_ascii=False, indent=6)}")
                print()

                print("ğŸ“Š æŸ¥è©¢çµæœæ‘˜è¦ï¼š")
                for idx, search_result in enumerate(result["search_results"], 1):
                    data = search_result.get("data", {})
                    total = data.get("totalCount", 0)
                    jobs_count = len(data.get("list", []))
                    print(f"   {idx}. æ‰¾åˆ° {total:,} ç­†å·¥ä½œï¼Œè¿”å› {jobs_count} ç­†")
                print()

            # é¡¯ç¤ºæœ€çµ‚å›æ‡‰
            print(f"ğŸ¤– åŠ©æ‰‹ï¼š{result['final_response']}")

        except Exception as e:
            print(f"âŒ éŒ¯èª¤ï¼š{e}")

        print()


if __name__ == "__main__":
    main()
